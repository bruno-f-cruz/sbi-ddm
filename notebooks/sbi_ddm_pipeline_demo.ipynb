{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Force CPU backend on Apple Silicon to avoid Metal issues\n",
    "# os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "# Disable LaTeX rendering in matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "import pickle\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from sbijax import NLE, plot_loss_profile\n",
    "from sbijax.nn import make_maf\n",
    "\n",
    "from vr_foraging_sbi_ddm.simulator import JaxPatchForagingDdm, create_prior\n",
    "from vr_foraging_sbi_ddm.snle.snle_inference_jax import infer_parameters_snle, train_snle\n",
    "from vr_foraging_sbi_ddm.snle.snle_utils_jax import extract_samples, get_model_directory, pairplot, plot_real_synth_hist\n",
    "from vr_foraging_sbi_ddm.validation import (\n",
    "    compute_sbc_metrics,\n",
    "    plot_recovery_scatter,\n",
    "    plot_sbc_diagnostics,\n",
    "    validate_parameter_recovery,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33255c",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vr_foraging_sbi_ddm.models import Config\n",
    "\n",
    "CONFIG = Config(n_simulations=500000, batch_size=256, n_iter=10000, n_early_stopping_patience=20, force_retrain=True)\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Model directory: {CONFIG.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Initialize and Train\n",
    "# ============================================================================\n",
    "\n",
    "simulator = JaxPatchForagingDdm(\n",
    "    initial_prob=0.8,\n",
    "    depletion_rate=-0.1,\n",
    "    threshold=1.0,\n",
    "    start_point=0.0,\n",
    "    interval_min=CONFIG.interval_min,\n",
    "    interval_scale=CONFIG.interval_scale,\n",
    "    interval_normalization=CONFIG.interval_normalization,\n",
    "    odor_site_length=CONFIG.odor_site_length,\n",
    "    max_sites_per_window=CONFIG.window_size,\n",
    "    n_feat=CONFIG.n_feat,\n",
    ")\n",
    "\n",
    "prior_fn = create_prior(prior_low=jnp.array(CONFIG.prior_low), prior_high=jnp.array(CONFIG.prior_high))\n",
    "\n",
    "print(\"Simulator initialized\")\n",
    "\n",
    "# Create model directory and get checkpoint directory\n",
    "model_dir, checkpoint_dir = get_model_directory(CONFIG)\n",
    "model_path = model_dir / \"model.pkl\"\n",
    "\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(f\"Model file: {model_path}\")\n",
    "\n",
    "if model_path.exists() and not CONFIG.force_retrain:\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_data = pickle.load(f)\n",
    "    snle = model_data[\"snle\"]\n",
    "    snle_params = model_data[\"snle_params\"]\n",
    "    y_mean = model_data[\"y_mean\"]\n",
    "    y_std = model_data[\"y_std\"]\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "else:\n",
    "    print(\"Training new SNLE model...\")\n",
    "    print(f\"Config: {CONFIG}\")\n",
    "\n",
    "    rng_key = random.PRNGKey(CONFIG.seed)\n",
    "\n",
    "    snle, snle_params, losses, rng_key, y_mean, y_std = train_snle(\n",
    "        simulator,\n",
    "        prior_fn,\n",
    "        mode=\"multi\",\n",
    "        n_simulations=CONFIG.n_simulations,\n",
    "        hidden_dim=CONFIG.hidden_dim,\n",
    "        num_layers=CONFIG.num_layers,\n",
    "        n_iter=CONFIG.n_iter,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        n_early_stopping_patience=CONFIG.n_early_stopping_patience,\n",
    "        learning_rate=CONFIG.learning_rate,\n",
    "        transition_steps=CONFIG.transition_steps,\n",
    "        decay_rate=CONFIG.decay_rate,\n",
    "        percentage_data_as_validation_set=0.1,\n",
    "        rng_key=rng_key,\n",
    "        save_dir=str(checkpoint_dir),\n",
    "        checkpoint_every=CONFIG.checkpoint_every,\n",
    "    )\n",
    "\n",
    "    # Save final model with descriptive filename\n",
    "    print(f\"\\nSaving final model to {model_path}\")\n",
    "    model_data = {\n",
    "        \"snle_params\": snle_params,\n",
    "        \"losses\": losses,\n",
    "        \"y_mean\": y_mean,\n",
    "        \"y_std\": y_std,\n",
    "        \"config\": CONFIG,\n",
    "        \"model_dir\": str(model_dir),\n",
    "        \"checkpoint_dir\": str(checkpoint_dir),\n",
    "    }\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "    print(f\"✓ Model saved successfully to {model_path}\")\n",
    "    print(f\"✓ Checkpoints saved in {checkpoint_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b03e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with descriptive filename\n",
    "print(f\"\\nSaving model to {model_path}\")\n",
    "model_data = {\n",
    "    \"snle_params\": snle_params,\n",
    "    \"losses\": losses,\n",
    "    \"y_mean\": y_mean,\n",
    "    \"y_std\": y_std,\n",
    "    \"config\": CONFIG.model_dump(),\n",
    "}\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✓ Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e977d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"results/snle_500K_lr0.001_ts5000_h128_l8_b256_37feat/model.pkl\"\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "from vr_foraging_sbi_ddm.plot_utils import a_lot_of_style\n",
    "with a_lot_of_style():\n",
    "    _, axes = plt.subplots(figsize=(6, 3))\n",
    "    plot_loss_profile(model_data[\"losses\"], axes)\n",
    "    #axes.set_ylim([-300, 100])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Config.model_validate(model_data[\"config\"])\n",
    "#with open(model_path, \"rb\") as f:\n",
    "#    model_data = pickle.load(f)\n",
    "\n",
    "# Reconstruct SNLE\n",
    "simulator = JaxPatchForagingDdm(max_sites_per_window=100, n_feat=CONFIG.n_feat)\n",
    "prior_fn = create_prior(prior_low=jnp.array(CONFIG.prior_low), prior_high=jnp.array(CONFIG.prior_high))\n",
    "\n",
    "rng_key = random.PRNGKey(CONFIG.seed)\n",
    "rng_key, test_key = random.split(rng_key)\n",
    "test_theta = prior_fn().sample(seed=test_key)\n",
    "test_x = simulator.simulator_fn(seed=test_key, theta=test_theta)\n",
    "n_features = test_x.shape[-1]\n",
    "\n",
    "flow = make_maf(\n",
    "    n_dimension=n_features,  # obs data dimension\n",
    "    n_layers=CONFIG.num_layers,\n",
    "    hidden_sizes=(CONFIG.hidden_dim, CONFIG.hidden_dim),\n",
    ")\n",
    "\n",
    "snle = NLE((prior_fn, simulator.simulator_fn), flow)\n",
    "\n",
    "print(\"✓ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate observed data ---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "true_theta = prior_fn().sample(seed=subkey)[\"theta\"]\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "_, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "print(f\"   True theta: {true_theta}\")\n",
    "print(f\"   Observed stats: {observed_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run inference ---\n",
    "print(\"\\n3. Testing inference...\")\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "posterior_samples, diagnostics = infer_parameters_snle(\n",
    "    snle,\n",
    "    model_data[\"snle_params\"],\n",
    "    observed_stats,\n",
    "    model_data[\"y_mean\"],\n",
    "    model_data[\"y_std\"],\n",
    "    num_samples=1_000,\n",
    "    num_warmup=500,\n",
    "    num_chains=4,\n",
    "    rng_key=subkey,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "# --- Plot posterior distributions ---\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "param_labels = [\n",
    "    \"drift_rate: evidence accumulation rate\",\n",
    "    \"reward_bump: evidence drop from receiving reward\",\n",
    "    \"failure_bump: evidence boost from not receiving reward\",\n",
    "    \"noise_std: std of noise in evidence accumulation\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(4):\n",
    "    # Compute histogram\n",
    "    counts, bins, _ = axes[i].hist(posterior_samples[:, i], bins=30, color=\"dodgerblue\", edgecolor=None, alpha=0.7)\n",
    "\n",
    "    # Posterior mode (bin center with max count)\n",
    "    mode_index = jnp.argmax(counts)\n",
    "    posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "    axes[i].axvline(true_theta[i], color=\"orangered\", linestyle=\"--\", label=\"true value\")\n",
    "    axes[i].axvline(posterior_mode, color=\"k\", linestyle=\"--\", label=\"MAP estimate\")\n",
    "\n",
    "    axes[i].set_xlabel(param_names[i])\n",
    "    axes[i].set_xlim(CONFIG.prior_low[i], CONFIG.prior_high[i])\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[i].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "pairplot(posterior_samples, true_theta, param_names, figsize_per_param=2.0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION: Parameter Recovery and SBC\n",
    "# ============================================================================\n",
    "# Note: Each test runs MCMC sampling which can take 30s-2min per test\n",
    "# For faster iteration during development, reduce n_tests to 3-5\n",
    "# For publication-quality validation, use n_tests >= 100 for SBC\n",
    "\n",
    "# Validation - Parameter Recovery\n",
    "print(\"=\" * 80)\n",
    "print(\"PARAMETER RECOVERY VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "results = validate_parameter_recovery(\n",
    "    snle, snle_params, y_mean, y_std, simulator, prior_fn, infer_parameters_snle, \n",
    "    n_tests=5,  # Originally 10\n",
    "    num_samples=1000,\n",
    "    num_warmup=500,\n",
    "    num_chains=4,\n",
    ")\n",
    "plot_recovery_scatter(results, save_path=\"recovery_results.png\")\n",
    "\n",
    "recovery_time = time.time() - start_time\n",
    "print(f\"\\n✓ Parameter recovery completed in {recovery_time:.2f} seconds ({recovery_time/60:.2f} minutes)\")\n",
    "\n",
    "# Full SBC - Compute metrics and plot diagnostics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SIMULATION-BASED CALIBRATION (SBC)\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "sbc_results = compute_sbc_metrics(\n",
    "    snle,\n",
    "    snle_params,\n",
    "    y_mean,\n",
    "    y_std,\n",
    "    simulator,\n",
    "    prior_fn,\n",
    "    infer_parameters_snle,\n",
    "    n_tests=20,  # Originally 100\n",
    "    num_samples=500,\n",
    "    num_warmup=100,\n",
    "    num_chains=2,\n",
    ")\n",
    "plot_sbc_diagnostics(sbc_results, bins=10, save_path=\"sbc_results.png\")\n",
    "\n",
    "sbc_time = time.time() - start_time\n",
    "print(f\"\\n✓ SBC completed in {sbc_time:.2f} seconds ({sbc_time/60:.2f} minutes)\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"TOTAL VALIDATION TIME: {recovery_time + sbc_time:.2f} seconds ({(recovery_time + sbc_time)/60:.2f} minutes)\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple patches from posterior samples to compare distributions\n",
    "print(\"\\nGenerating patches from posterior samples for comparison...\")\n",
    "num_window_sites = 500\n",
    "\n",
    "# --- Simulate 'real' data from simulator---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "real_data = []\n",
    "for i_site in range(num_window_sites):\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, data = simulator.simulate_one_window(true_theta, subkey)\n",
    "    real_data.append(data)\n",
    "real_data = np.array(real_data)\n",
    "\n",
    "# # 2. Generate \"synthetic\" data from simulator using posterior-sampled parameters\n",
    "# Get observed summary stats\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "_, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "obs_norm = (observed_stats - y_mean) / y_std\n",
    "\n",
    "# Sample posterior θ using ONE observation\n",
    "rng_key, sub = random.split(rng_key)\n",
    "inference_results, diagnostics = snle.sample_posterior(\n",
    "    sub,\n",
    "    snle_params,\n",
    "    observable=obs_norm,\n",
    "    n_samples=500,\n",
    "    n_chains=1,\n",
    "    n_warmup=200,\n",
    ")\n",
    "\n",
    "posterior_ds = extract_samples(inference_results)\n",
    "theta_samples = posterior_ds[\"theta\"].values.reshape(-1, 4)  # shape (500,4)\n",
    "\n",
    "# Simulate synthetic patches for comparison\n",
    "posterior_mean_theta = theta_samples.mean(axis=0)  # Single point estimate\n",
    "\n",
    "synthetic_data = []\n",
    "for i in range(500):\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, data = simulator.simulate_one_window(posterior_mean_theta, subkey)\n",
    "    synthetic_data.append(data)\n",
    "synthetic_data = jnp.array(synthetic_data)\n",
    "\n",
    "# 4. Plot\n",
    "plot_real_synth_hist(real_data, synthetic_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi-ddm (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
