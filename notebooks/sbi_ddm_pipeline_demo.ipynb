{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CPU backend on Apple Silicon to avoid Metal issues\n",
    "# os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "# Disable LaTeX rendering in matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"DejaVu Serif\"],\n",
    "})\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from sbijax import NLE, plot_loss_profile\n",
    "from sbijax.nn import make_maf\n",
    "\n",
    "from vr_foraging_sbi_ddm.simulator import JaxPatchForagingDdm, create_prior\n",
    "\n",
    "# SNLE (Option A)\n",
    "from vr_foraging_sbi_ddm.snle.snle_inference_jax import infer_parameters_snle, train_snle\n",
    "# NPE (Option B)\n",
    "from vr_foraging_sbi_ddm.snle.npe_inference_jax import infer_parameters_npe, train_npe\n",
    "\n",
    "# Shared utilities\n",
    "from vr_foraging_sbi_ddm.snle.snle_utils_jax import (\n",
    "    extract_samples, get_model_directory, pairplot, plot_real_synth_hist,\n",
    ")\n",
    "from vr_foraging_sbi_ddm.validation import (\n",
    "    compute_sbc_metrics,\n",
    "    plot_recovery_scatter,\n",
    "    plot_sbc_diagnostics,\n",
    "    validate_parameter_recovery,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33255c",
   "metadata": {},
   "source": [
    "# Shared Setup\n",
    "The cells below (Configuration, Simulator, Prior) are shared by both pipelines.\n",
    "Run these first, then choose **Option A** (SNLE + MCMC) or **Option B** (NPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb41d",
   "metadata": {},
   "outputs": [],
   "source": "from vr_foraging_sbi_ddm.models import Config\n\nCONFIG = Config(n_simulations=500000, batch_size=256, n_iter=100000, n_early_stopping_patience=20, force_retrain=True)\nprint(\"Configuration loaded\")\nprint(f\"Model directory: {CONFIG.filename}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Shared: Initialize simulator and prior\n",
    "# ============================================================================\n",
    "\n",
    "simulator = JaxPatchForagingDdm(\n",
    "    initial_prob=0.8,\n",
    "    depletion_rate=-0.1,\n",
    "    threshold=1.0,\n",
    "    start_point=0.0,\n",
    "    interval_min=CONFIG.interval_min,\n",
    "    interval_scale=CONFIG.interval_scale,\n",
    "    interval_normalization=CONFIG.interval_normalization,\n",
    "    odor_site_length=CONFIG.odor_site_length,\n",
    "    max_sites_per_window=CONFIG.window_size,\n",
    "    n_feat=CONFIG.n_feat,\n",
    ")\n",
    "\n",
    "prior_fn = create_prior(prior_low=jnp.array(CONFIG.prior_low), prior_high=jnp.array(CONFIG.prior_high))\n",
    "rng_key = random.PRNGKey(CONFIG.seed)\n",
    "\n",
    "print(\"Simulator initialized\")\n",
    "print(f\"Prior bounds: {CONFIG.prior_low} -> {CONFIG.prior_high}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b03e50",
   "metadata": {},
   "source": [
    "# Option A: SNLE + MCMC (Exact, Slower)\n",
    "\n",
    "Sequential Neural Likelihood Estimation learns $p(x | \\\\theta)$ and uses MCMC to sample the posterior.\n",
    "\n",
    "**Pros**: Exact posterior, reusable likelihood\n",
    "**Cons**: MCMC is slow (~seconds per observation), requires warmup and convergence diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ylng5fsk0ih",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# A1: Train SNLE\n",
    "# ============================================================================\n",
    "\n",
    "model_dir, checkpoint_dir = get_model_directory(CONFIG)\n",
    "model_path = model_dir / \"model.pkl\"\n",
    "\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "\n",
    "if model_path.exists() and not CONFIG.force_retrain:\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_data = pickle.load(f)\n",
    "    snle_params = model_data[\"snle_params\"]\n",
    "    y_mean = model_data[\"y_mean\"]\n",
    "    y_std = model_data[\"y_std\"]\n",
    "\n",
    "    # Reconstruct SNLE object\n",
    "    rng_key, test_key = random.split(rng_key)\n",
    "    test_theta = prior_fn().sample(seed=test_key)\n",
    "    test_x = simulator.simulator_fn(seed=test_key, theta=test_theta)\n",
    "    flow = make_maf(\n",
    "        n_dimension=test_x.shape[-1],\n",
    "        n_layers=CONFIG.num_layers,\n",
    "        hidden_sizes=(CONFIG.hidden_dim, CONFIG.hidden_dim),\n",
    "    )\n",
    "    snle = NLE((prior_fn, simulator.simulator_fn), flow)\n",
    "    print(\"✓ Model loaded\")\n",
    "else:\n",
    "    print(\"Training new SNLE model...\")\n",
    "    snle, snle_params, losses, rng_key, y_mean, y_std = train_snle(\n",
    "        simulator,\n",
    "        prior_fn,\n",
    "        mode=\"multi\",\n",
    "        n_simulations=CONFIG.n_simulations,\n",
    "        hidden_dim=CONFIG.hidden_dim,\n",
    "        num_layers=CONFIG.num_layers,\n",
    "        n_iter=CONFIG.n_iter,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        n_early_stopping_patience=CONFIG.n_early_stopping_patience,\n",
    "        learning_rate=CONFIG.learning_rate,\n",
    "        transition_steps=CONFIG.transition_steps,\n",
    "        decay_rate=CONFIG.decay_rate,\n",
    "        percentage_data_as_validation_set=0.1,\n",
    "        rng_key=rng_key,\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    model_data = {\n",
    "        \"snle_params\": snle_params,\n",
    "        \"losses\": losses,\n",
    "        \"y_mean\": y_mean,\n",
    "        \"y_std\": y_std,\n",
    "        \"config\": CONFIG.model_dump(),\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    print(f\"✓ Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# A2: Simulate test observation + SNLE inference\n",
    "# ============================================================================\n",
    "\n",
    "# Simulate a test observation\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "true_theta = prior_fn().sample(seed=subkey)[\"theta\"]\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "_, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "print(f\"True theta: {true_theta}\")\n",
    "print(f\"Observed stats shape: {observed_stats.shape}\")\n",
    "\n",
    "# Run SNLE + MCMC inference\n",
    "start_time = time.time()\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "posterior_samples, diagnostics = infer_parameters_snle(\n",
    "    snle,\n",
    "    snle_params,\n",
    "    observed_stats,\n",
    "    y_mean,\n",
    "    y_std,\n",
    "    num_samples=1_000,\n",
    "    num_warmup=500,\n",
    "    num_chains=4,\n",
    "    rng_key=subkey,\n",
    ")\n",
    "snle_time = time.time() - start_time\n",
    "print(f\"\\nSNLE inference time: {snle_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# A3: Plot SNLE posteriors\n",
    "# ============================================================================\n",
    "\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "fig.suptitle(\"SNLE + MCMC Posterior\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "for i in range(4):\n",
    "    counts, bins, _ = axes[i].hist(posterior_samples[:, i], bins=30, color=\"dodgerblue\", edgecolor=None, alpha=0.7)\n",
    "    mode_index = jnp.argmax(counts)\n",
    "    posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "    axes[i].axvline(true_theta[i], color=\"orangered\", linestyle=\"--\", label=\"true value\")\n",
    "    axes[i].axvline(posterior_mode, color=\"k\", linestyle=\"--\", label=\"MAP estimate\")\n",
    "    axes[i].set_xlabel(param_names[i])\n",
    "    axes[i].set_xlim(CONFIG.prior_low[i], CONFIG.prior_high[i])\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[-1].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "\n",
    "pairplot(posterior_samples, true_theta, param_names, figsize_per_param=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# A4: SNLE Validation (Parameter Recovery + SBC)\n",
    "# ============================================================================\n",
    "# Note: Each test runs MCMC sampling — can take 30s-2min per test.\n",
    "# For faster iteration, reduce n_tests. For publication, use n_tests >= 100.\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNLE PARAMETER RECOVERY\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "recovery_results_snle = validate_parameter_recovery(\n",
    "    snle, snle_params, y_mean, y_std, simulator, prior_fn, infer_parameters_snle,\n",
    "    n_tests=5,\n",
    "    num_samples=1000,\n",
    "    num_warmup=500,\n",
    "    num_chains=4,\n",
    ")\n",
    "plot_recovery_scatter(recovery_results_snle, save_path=\"snle_recovery.png\")\n",
    "\n",
    "recovery_time = time.time() - start_time\n",
    "print(f\"\\n✓ Recovery completed in {recovery_time:.1f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SNLE SBC\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "sbc_results_snle = compute_sbc_metrics(\n",
    "    snle, snle_params, y_mean, y_std, simulator, prior_fn, infer_parameters_snle,\n",
    "    n_tests=20,\n",
    "    num_samples=500,\n",
    "    num_warmup=100,\n",
    "    num_chains=2,\n",
    ")\n",
    "plot_sbc_diagnostics(sbc_results_snle, bins=10, save_path=\"snle_sbc.png\")\n",
    "\n",
    "sbc_time = time.time() - start_time\n",
    "print(f\"\\n✓ SBC completed in {sbc_time:.1f}s\")\n",
    "print(f\"Total SNLE validation: {recovery_time + sbc_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tvp6ii7cx8e",
   "metadata": {},
   "source": [
    "# Option B: NPE (Fast, Approximate)\n",
    "\n",
    "Neural Posterior Estimation learns $p(\\theta | x)$ directly and samples via a single forward pass — no MCMC needed.\n",
    "\n",
    "**Pros**: ~1000x faster inference.\n",
    "**Cons**: Cannot do sequential rounds, susceptible to prior leakage, not reusable with different priors (see Papamakarios et al. 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rspz3bxgn8l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# B1: Train NPE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Training new NPE model...\")\n",
    "\n",
    "npe, npe_params, npe_losses, rng_key, npe_y_mean, npe_y_std = train_npe(\n",
    "    simulator,\n",
    "    prior_fn,\n",
    "    n_simulations=CONFIG.n_simulations,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    num_layers=CONFIG.num_layers,\n",
    "    n_iter=CONFIG.n_iter,\n",
    "    batch_size=CONFIG.batch_size,\n",
    "    n_early_stopping_patience=CONFIG.n_early_stopping_patience,\n",
    "    learning_rate=CONFIG.learning_rate,\n",
    "    transition_steps=CONFIG.transition_steps,\n",
    "    decay_rate=CONFIG.decay_rate,\n",
    "    percentage_data_as_validation_set=0.1,\n",
    "    rng_key=rng_key,\n",
    ")\n",
    "\n",
    "print(\"✓ NPE training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0rythbdebna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# B2: Simulate test observation + NPE inference\n",
    "# ============================================================================\n",
    "\n",
    "# Use the same test observation as SNLE (if available), or generate a new one\n",
    "if \"true_theta\" not in dir() or true_theta is None:\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    true_theta = prior_fn().sample(seed=subkey)[\"theta\"]\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "    print(f\"True theta: {true_theta}\")\n",
    "\n",
    "# Run NPE inference (direct sampling — no MCMC)\n",
    "start_time = time.time()\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "npe_posterior_samples, npe_diagnostics = infer_parameters_npe(\n",
    "    npe,\n",
    "    npe_params,\n",
    "    observed_stats,\n",
    "    npe_y_mean,\n",
    "    npe_y_std,\n",
    "    num_samples=4_000,\n",
    "    rng_key=subkey,\n",
    ")\n",
    "npe_time = time.time() - start_time\n",
    "print(f\"\\nNPE inference time: {npe_time:.4f}s\")\n",
    "\n",
    "if \"snle_time\" in dir():\n",
    "    print(f\"SNLE inference time: {snle_time:.2f}s\")\n",
    "    print(f\"Speedup: {snle_time / npe_time:.0f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x1je77ggs2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# B3: Plot NPE posteriors\n",
    "# ============================================================================\n",
    "\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "fig.suptitle(\"NPE Posterior (Direct Sampling)\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "for i in range(4):\n",
    "    counts, bins, _ = axes[i].hist(npe_posterior_samples[:, i], bins=30, color=\"coral\", edgecolor=None, alpha=0.7)\n",
    "    mode_index = jnp.argmax(counts)\n",
    "    posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "    axes[i].axvline(true_theta[i], color=\"orangered\", linestyle=\"--\", label=\"true value\")\n",
    "    axes[i].axvline(posterior_mode, color=\"k\", linestyle=\"--\", label=\"MAP estimate\")\n",
    "    axes[i].set_xlabel(param_names[i])\n",
    "    axes[i].set_xlim(CONFIG.prior_low[i], CONFIG.prior_high[i])\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[-1].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "\n",
    "pairplot(npe_posterior_samples, true_theta, param_names, figsize_per_param=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316yiv034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# B4: NPE Validation (Parameter Recovery + SBC)\n",
    "# ============================================================================\n",
    "# NPE validation is MUCH faster since no MCMC is needed per test.\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NPE PARAMETER RECOVERY\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "recovery_results_npe = validate_parameter_recovery(\n",
    "    npe, npe_params, npe_y_mean, npe_y_std, simulator, prior_fn, infer_parameters_npe,\n",
    "    n_tests=5,\n",
    "    num_samples=4000,\n",
    "    num_warmup=0,   # ignored by NPE\n",
    "    num_chains=1,   # ignored by NPE\n",
    ")\n",
    "plot_recovery_scatter(recovery_results_npe, save_path=\"npe_recovery.png\")\n",
    "\n",
    "npe_recovery_time = time.time() - start_time\n",
    "print(f\"\\n✓ NPE recovery completed in {npe_recovery_time:.1f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NPE SBC\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "sbc_results_npe = compute_sbc_metrics(\n",
    "    npe, npe_params, npe_y_mean, npe_y_std, simulator, prior_fn, infer_parameters_npe,\n",
    "    n_tests=20,\n",
    "    num_samples=2000,\n",
    "    num_warmup=0,   # ignored by NPE\n",
    "    num_chains=1,   # ignored by NPE\n",
    ")\n",
    "plot_sbc_diagnostics(sbc_results_npe, bins=10, save_path=\"npe_sbc.png\")\n",
    "\n",
    "npe_sbc_time = time.time() - start_time\n",
    "print(f\"\\n✓ NPE SBC completed in {npe_sbc_time:.1f}s\")\n",
    "print(f\"Total NPE validation: {npe_recovery_time + npe_sbc_time:.1f}s\")\n",
    "\n",
    "if \"recovery_time\" in dir() and \"sbc_time\" in dir():\n",
    "    snle_total = recovery_time + sbc_time\n",
    "    npe_total = npe_recovery_time + npe_sbc_time\n",
    "    print(f\"\\nSNLE validation total: {snle_total:.1f}s\")\n",
    "    print(f\"NPE validation total:  {npe_total:.1f}s\")\n",
    "    print(f\"Speedup: {snle_total / npe_total:.1f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi-ddm (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}