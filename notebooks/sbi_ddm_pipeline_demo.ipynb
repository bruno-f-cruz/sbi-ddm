{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf5d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\git\\AllenNeuralDynamics\\sbi-ddm\\.venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git\\AllenNeuralDynamics\\sbi-ddm\\.venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\jax\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\AllenNeuralDynamics\\sbi-ddm\\.venv\\Lib\\site-packages\\arviz\\__init__.py:50: FutureWarning: \n",
      "ArviZ is undergoing a major refactor to improve flexibility and extensibility while maintaining a user-friendly interface.\n",
      "Some upcoming changes may be backward incompatible.\n",
      "For details and migration guidance, visit: https://python.arviz.org/en/latest/user_guide/migration_guide.html\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Force CPU backend on Apple Silicon to avoid Metal issues\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "# Disable LaTeX rendering in matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from sbijax import NLE, plot_loss_profile\n",
    "from sbijax.nn import make_maf\n",
    "\n",
    "from vr_foraging_sbi_ddm.simulator import PatchForagingDDM_JAX, create_prior\n",
    "from vr_foraging_sbi_ddm.snle.snle_inference_jax import infer_parameters_snle, train_snle\n",
    "from vr_foraging_sbi_ddm.snle.snle_utils_jax import extract_samples, get_model_directory, pairplot, plot_real_synth_hist\n",
    "from vr_foraging_sbi_ddm.validation import plot_recovery_scatter, run_sbc_evaluation, validate_parameter_recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    \"base_path\": Path(\"/Users/laura.driscoll/Documents/data/VR foraging/vr_foraging_data\"),\n",
    "    \"base_output_dir\": Path(\"/Users/laura.driscoll/Documents/code/sbi_results\"),\n",
    "    \"filename\": [],\n",
    "    \"window_size\": 100,\n",
    "    \"n_feat\": 37,\n",
    "    \"odor_types\": [\"Methyl_Butyrate\", \"Alpha_pinene\"],\n",
    "    \"odor_display_names\": {\"Methyl_Butyrate\": \"Methyl Butyrate\", \"Alpha_pinene\": \"Alpha-pinene\"},\n",
    "    \"interval_min\": 20.0,\n",
    "    \"interval_scale\": 19.0,\n",
    "    \"odor_site_length\": 50.0,\n",
    "    \"interval_normalization\": 88.73,\n",
    "    \"prior_low\": [-0.3, -1.3, -0.3, 0.0],\n",
    "    \"prior_high\": [1.3, 1.3, 2, 0.3],\n",
    "    \"n_simulations\": 2_000_000,\n",
    "    \"n_iter\": 1000,\n",
    "    \"batch_size\": 256,\n",
    "    \"n_early_stopping_patience\": 5,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"num_layers\": 8,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"transition_steps\": 5000,\n",
    "    \"decay_rate\": 0.999,\n",
    "    \"checkpoint_every\": 20,  # Save checkpoint every 20 iterations\n",
    "    \"force_retrain\": False,  # loads model that has already been trained if False, otherwise retrains from scratch even if model files exist\n",
    "    \"num_samples\": 500,\n",
    "    \"num_warmup\": 200,\n",
    "    \"num_chains\": 2,\n",
    "    \"seed\": 0,\n",
    "}\n",
    "\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Model directory: {CONFIG['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Initialize and Train\n",
    "# ============================================================================\n",
    "\n",
    "simulator = PatchForagingDDM_JAX(\n",
    "    initial_prob=0.8,\n",
    "    depletion_rate=-0.1,\n",
    "    threshold=1.0,\n",
    "    start_point=0.0,\n",
    "    interval_min=CONFIG[\"interval_min\"],\n",
    "    interval_scale=CONFIG[\"interval_scale\"],\n",
    "    interval_normalization=CONFIG[\"interval_normalization\"],\n",
    "    odor_site_length=CONFIG[\"odor_site_length\"],\n",
    "    max_sites_per_window=CONFIG[\"window_size\"],\n",
    "    n_feat=CONFIG[\"n_feat\"],\n",
    ")\n",
    "\n",
    "prior_fn = create_prior(prior_low=jnp.array(CONFIG[\"prior_low\"]), prior_high=jnp.array(CONFIG[\"prior_high\"]))\n",
    "\n",
    "print(\"Simulator initialized\")\n",
    "\n",
    "# Create model directory and get checkpoint directory\n",
    "model_dir, checkpoint_dir = get_model_directory(CONFIG)\n",
    "model_path = model_dir / \"model.pkl\"\n",
    "\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(f\"Model file: {model_path}\")\n",
    "\n",
    "if model_path.exists() and not CONFIG[\"force_retrain\"]:\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_data = pickle.load(f)\n",
    "    snle = model_data[\"snle\"]\n",
    "    snle_params = model_data[\"snle_params\"]\n",
    "    y_mean = model_data[\"y_mean\"]\n",
    "    y_std = model_data[\"y_std\"]\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "else:\n",
    "    print(\"Training new SNLE model...\")\n",
    "    print(f\"Config: {CONFIG}\")\n",
    "\n",
    "    rng_key = random.PRNGKey(CONFIG[\"seed\"])\n",
    "\n",
    "    snle, snle_params, losses, rng_key, y_mean, y_std = train_snle(\n",
    "        simulator,\n",
    "        prior_fn,\n",
    "        mode=\"multi\",\n",
    "        n_simulations=CONFIG[\"n_simulations\"],\n",
    "        hidden_dim=CONFIG[\"hidden_dim\"],\n",
    "        num_layers=CONFIG[\"num_layers\"],\n",
    "        n_iter=CONFIG[\"n_iter\"],\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        n_early_stopping_patience=CONFIG[\"n_early_stopping_patience\"],\n",
    "        learning_rate=CONFIG[\"learning_rate\"],\n",
    "        transition_steps=CONFIG[\"transition_steps\"],\n",
    "        decay_rate=CONFIG[\"decay_rate\"],\n",
    "        percentage_data_as_validation_set=0.1,\n",
    "        rng_key=rng_key,\n",
    "        save_dir=str(checkpoint_dir),\n",
    "        checkpoint_every=CONFIG[\"checkpoint_every\"],\n",
    "    )\n",
    "\n",
    "    # Save final model with descriptive filename\n",
    "    print(f\"\\nSaving final model to {model_path}\")\n",
    "    model_data = {\n",
    "        \"snle_params\": snle_params,\n",
    "        \"losses\": losses,\n",
    "        \"y_mean\": y_mean,\n",
    "        \"y_std\": y_std,\n",
    "        \"config\": CONFIG,\n",
    "        \"model_dir\": str(model_dir),\n",
    "        \"checkpoint_dir\": str(checkpoint_dir),\n",
    "    }\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "    print(f\"✓ Model saved successfully to {model_path}\")\n",
    "    print(f\"✓ Checkpoints saved in {checkpoint_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b03e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with descriptive filename\n",
    "print(f\"\\nSaving model to {model_path}\")\n",
    "model_data = {\n",
    "    \"snle_params\": snle_params,\n",
    "    \"losses\": losses,\n",
    "    \"y_mean\": y_mean,\n",
    "    \"y_std\": y_std,\n",
    "    \"config\": CONFIG,\n",
    "}\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✓ Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e977d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/laura.driscoll/Documents/code/sbi_results/snle_2M_lr0.0004_ts2000_h128_l8_b128_37feat/model.pkl\"\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "# Disable LaTeX rendering in matplotlib\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "_, axes = plt.subplots(figsize=(6, 3))\n",
    "plot_loss_profile(model_data[\"losses\"], axes)\n",
    "axes.set_ylim([-300, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = model_data[\"config\"]\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "# Reconstruct SNLE\n",
    "simulator = PatchForagingDDM_JAX(max_sites_per_window=100, n_feat=CONFIG[\"n_feat\"])\n",
    "prior_fn = create_prior(prior_low=jnp.array(CONFIG[\"prior_low\"]), prior_high=jnp.array(CONFIG[\"prior_high\"]))\n",
    "\n",
    "rng_key = random.PRNGKey(CONFIG[\"seed\"])\n",
    "rng_key, test_key = random.split(rng_key)\n",
    "test_theta = prior_fn().sample(seed=test_key)\n",
    "test_x = simulator.simulator_fn(seed=test_key, theta=test_theta)\n",
    "n_features = test_x.shape[-1]\n",
    "\n",
    "flow = make_maf(\n",
    "    n_dimension=n_features,  # obs data dimension\n",
    "    n_layers=CONFIG[\"num_layers\"],\n",
    "    hidden_sizes=(CONFIG[\"hidden_dim\"], CONFIG[\"hidden_dim\"]),\n",
    ")\n",
    "\n",
    "snle = NLE((prior_fn, simulator.simulator_fn), flow)\n",
    "\n",
    "print(\"✓ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate observed data ---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "true_theta = prior_fn().sample(seed=subkey)[\"theta\"]\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "_, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "print(f\"   True theta: {true_theta}\")\n",
    "print(f\"   Observed stats: {observed_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run inference ---\n",
    "print(\"\\n3. Testing inference...\")\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "posterior_samples, diagnostics = infer_parameters_snle(\n",
    "    snle,\n",
    "    model_data[\"snle_params\"],\n",
    "    observed_stats,\n",
    "    model_data[\"y_mean\"],\n",
    "    model_data[\"y_std\"],\n",
    "    num_samples=1_000,\n",
    "    num_warmup=500,\n",
    "    num_chains=4,\n",
    "    rng_key=subkey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot posterior distributions ---\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "param_labels = [\n",
    "    \"drift_rate: evidence accumulation rate\",\n",
    "    \"reward_bump: evidence drop from receiving reward\",\n",
    "    \"failure_bump: evidence boost from not receiving reward\",\n",
    "    \"noise_std: std of noise in evidence accumulation\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(4):\n",
    "    # Compute histogram\n",
    "    counts, bins, _ = axes[i].hist(posterior_samples[:, i], bins=30, color=\"dodgerblue\", edgecolor=None, alpha=0.7)\n",
    "\n",
    "    # Posterior mode (bin center with max count)\n",
    "    mode_index = jnp.argmax(counts)\n",
    "    posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "    axes[i].axvline(true_theta[i], color=\"orangered\", linestyle=\"--\", label=\"true value\")\n",
    "    axes[i].axvline(posterior_mode, color=\"k\", linestyle=\"--\", label=\"MAP estimate\")\n",
    "\n",
    "    axes[i].set_xlabel(param_names[i])\n",
    "    axes[i].set_xlim(CONFIG[\"prior_low\"][i], CONFIG[\"prior_high\"][i])\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[i].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(posterior_samples, true_theta, param_names, figsize_per_param=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "results = validate_parameter_recovery(\n",
    "    snle, snle_params, y_mean, y_std, simulator, prior_fn, infer_parameters_snle, n_tests=10\n",
    ")\n",
    "plot_recovery_scatter(results)\n",
    "\n",
    "# Full SBC\n",
    "ranks, z_scores = run_sbc_evaluation(\n",
    "    snle,\n",
    "    snle_params,\n",
    "    y_mean,\n",
    "    y_std,\n",
    "    simulator,\n",
    "    prior_fn,\n",
    "    infer_parameters_snle,\n",
    "    n_tests=100,\n",
    "    save_path=\"sbc_results.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple patches from posterior samples to compare distributions\n",
    "print(\"\\nGenerating patches from posterior samples for comparison...\")\n",
    "\n",
    "num_window_sites = 500\n",
    "\n",
    "# --- Simulate 'real' data from simulator---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "real_data = []\n",
    "for i_site in range(num_window_sites):\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, data = simulator.simulate_one_window(true_theta, subkey)\n",
    "    real_data.append(data)\n",
    "real_data = np.array(real_data)\n",
    "\n",
    "# # 2. Generate \"synthetic\" data from simulator using posterior-sampled parameters\n",
    "# Get observed summary stats\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "_, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "obs_norm = (observed_stats - y_mean) / y_std\n",
    "\n",
    "# Sample posterior θ using ONE observation\n",
    "rng_key, sub = random.split(rng_key)\n",
    "inference_results, diagnostics = snle.sample_posterior(\n",
    "    sub,\n",
    "    snle_params,\n",
    "    observable=obs_norm,\n",
    "    n_samples=500,\n",
    "    n_chains=1,\n",
    "    n_warmup=200,\n",
    ")\n",
    "\n",
    "posterior_ds = extract_samples(inference_results)\n",
    "theta_samples = posterior_ds[\"theta\"].values.reshape(-1, 4)  # shape (500,4)\n",
    "\n",
    "# Simulate synthetic patches for comparison\n",
    "posterior_mean_theta = theta_samples.mean(axis=0)  # Single point estimate\n",
    "\n",
    "synthetic_data = []\n",
    "for i in range(500):\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, data = simulator.simulate_one_window(posterior_mean_theta, subkey)\n",
    "    synthetic_data.append(data)\n",
    "synthetic_data = jnp.array(synthetic_data)\n",
    "\n",
    "# 4. Plot\n",
    "plot_real_synth_hist(real_data, synthetic_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi-ddm (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
