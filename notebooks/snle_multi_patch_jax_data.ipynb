{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Force CPU backend on Apple Silicon to avoid Metal issues\n",
    "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Disable LaTeX rendering in matplotlib\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "from sbijax import plot_loss_profile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from aind_behavior_vrforaging_analysis.sbi_ddm_analysis.simulator import PatchForagingDDM_JAX, create_prior\n",
    "from aind_behavior_vrforaging_analysis.sbi_ddm_analysis.snle.snle_inference_jax import infer_parameters_snle\n",
    "from sbijax import NLE\n",
    "from sbijax.nn import make_maf\n",
    "\n",
    "# Load saved parameters \n",
    "# model_name = 'snle_2M_h128_l8_b256_37feat.pkl'# 'snle_2M_h128_l8_b256_1feat' #''snle_2M_h128_l8_b1024_300feat' # 'snle_2M_h128_l8_b2048_300feat' #'snle_5M_h128_l8_b256_37feat' #'snle_2M_h64_l5_b256_37feat'\n",
    "# model_name = 'snle_2M_lr0.0001_ts2000_h128_l8_b256_37feat/model'\n",
    "model_name = 'snle_2M_lr0.0002_ts2000_h128_l8_b256_37feat'\n",
    "model_name = 'snle_2M_lr0.0005_ts2000_h128_l8_b256_37feat'\n",
    "model_name = 'snle_2M_lr0.0005_ts2000_h128_l8_b128_37feat' # w negative drift in prior\n",
    "# model_name = 'snle_2M_lr0.0008_ts2000_h128_l8_b128_37feat' # w negative drift in prior faster learning rate\n",
    "model_name = 'snle_2M_lr0.0009_ts2000_h128_l8_b128_37feat' #latest model with negative drift in prior and faster learning rate\n",
    "with open(f'/Users/laura.driscoll/Documents/code/sbi_results/{model_name}/model.pkl', 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "# Reconstruct the model\n",
    "simulator = PatchForagingDDM_JAX(\n",
    "    max_sites_per_window=100,\n",
    "    interval_normalization=model_data['config']['interval_normalization']\n",
    ")\n",
    "prior_fn = create_prior(\n",
    "    prior_low=jnp.array(model_data['config']['prior_low']),\n",
    "    prior_high=jnp.array(model_data['config']['prior_high'])\n",
    ")\n",
    "\n",
    "rng_key = random.PRNGKey(model_data['config']['seed']+1)\n",
    "rng_key, test_key = random.split(rng_key)\n",
    "test_theta = prior_fn().sample(seed=test_key)\n",
    "test_x = simulator.simulator_fn(seed=test_key, theta=test_theta)\n",
    "n_features = test_x.shape[-1]\n",
    "\n",
    "# Rebuild the flow architecture (must match training)\n",
    "flow = make_maf(\n",
    "    n_dimension=n_features,  # obs data dimension\n",
    "    n_layers=model_data['config']['num_layers'],\n",
    "    hidden_sizes=(model_data['config']['hidden_dim'], model_data['config']['hidden_dim'])\n",
    ")\n",
    "\n",
    "# Create SNLE model\n",
    "fns = prior_fn, simulator.simulator_fn\n",
    "snle = NLE(fns, flow)\n",
    "\n",
    "print(\"Model reconstructed! Ready for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e601dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable LaTeX rendering in matplotlib\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "_, axes = plt.subplots(figsize=(6, 3))\n",
    "plot_loss_profile(model_data['losses'], axes)\n",
    "# axes.set_ylim(bottom=-200,top=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load Real Data Statistics BY ODOR TYPE\n",
    "# ============================================================================\n",
    "\n",
    "# Path to processed data\n",
    "base_path = Path(\"/Users/laura.driscoll/Documents/data/VR foraging/vr_foraging_data\")\n",
    "\n",
    "# Load batch processing results\n",
    "results_df = pd.read_csv(base_path / \"batch_processing_by_odor_results.csv\")\n",
    "successful_sessions = results_df[results_df['status'] == 'success']\n",
    "\n",
    "# Define odor types to analyze\n",
    "odor_types = ['Methyl_Butyrate', 'Alpha_pinene']\n",
    "odor_display_names = {'Methyl_Butyrate': 'Methyl Butyrate', 'Alpha_pinene': 'Alpha-pinene'}\n",
    "odor_type = odor_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in successful_sessions.iterrows():\n",
    "    # print(idx)\n",
    "    print(row)\n",
    "\n",
    "    session_dir = Path(row['session_dir'])\n",
    "    odor_dir = session_dir / \"100_window_data_by_odor\" / odor_type\n",
    "\n",
    "    # Load metadata\n",
    "    with open(odor_dir / \"metadata.json\", 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Load all windows for this odor\n",
    "    n_windows = metadata['n_windows']\n",
    "    session_windows = []\n",
    "    for i in range(n_windows):\n",
    "        window = np.load(odor_dir / f\"window_{i:03d}.npy\")\n",
    "        session_windows.append(window)\n",
    "\n",
    "    session_windows = np.array(session_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "param_labels = [\n",
    "    \"drift_rate: evidence accumulation rate\",\n",
    "    \"reward_bump: evidence boost from receiving reward\",\n",
    "    \"failure_bump: evidence boost from not receiving reward\",\n",
    "    \"noise_std: std of noise in evidence accumulation\"\n",
    "]\n",
    "cmap = plt.colormaps['rainbow']\n",
    "number_of_samples = 9\n",
    "\n",
    "for idx, row in successful_sessions.iterrows():\n",
    "    # print(idx)\n",
    "    print(row)\n",
    "\n",
    "    session_dir = Path(row['session_dir'])\n",
    "    odor_dir = session_dir / \"100_window_data_by_odor\" / odor_type\n",
    "\n",
    "    # Load metadata\n",
    "    with open(odor_dir / \"metadata.json\", 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Load all windows for this odor\n",
    "    n_windows = metadata['n_windows']\n",
    "    session_windows = []\n",
    "    for i in range(n_windows):\n",
    "        window = np.load(odor_dir / f\"window_{i:03d}.npy\")\n",
    "        session_windows.append(window)\n",
    "\n",
    "    session_windows = np.array(session_windows)\n",
    "\n",
    "    # 3. Sample the colormap at regular intervals from 0 to 1\n",
    "    # This returns an array of RGBA tuples\n",
    "    gradient = np.linspace(0, 1, number_of_samples)\n",
    "    colors_rgba = cmap(gradient)\n",
    "    drift_values = np.linspace(0, 1, number_of_samples)*2\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for session_i in range(n_windows-1):\n",
    "\n",
    "        n_feat = model_data['config']['n_feat']\n",
    "        window_data = session_windows[session_i,:,:]\n",
    "        window_data[:,0] = window_data[:,0]/model_data['config']['interval_normalization']\n",
    "\n",
    "        if n_feat == 300:\n",
    "            observed_stats = prepare_raw_data(window_data)\n",
    "        elif n_feat == 23:\n",
    "            from aind_behavior_vrforaging_analysis.sbi_ddm_analysis.feature_engineering.enhanced_stats_23 import compute_summary_stats\n",
    "            observed_stats = compute_summary_stats(window_data)\n",
    "        elif n_feat == 35:\n",
    "            from aind_behavior_vrforaging_analysis.sbi_ddm_analysis.feature_engineering.enhanced_stats_35 import compute_summary_stats\n",
    "            observed_stats = compute_summary_stats(window_data)\n",
    "        elif n_feat == 37:\n",
    "            from aind_behavior_vrforaging_analysis.sbi_ddm_analysis.feature_engineering.enhanced_stats_37 import compute_summary_stats\n",
    "            observed_stats = compute_summary_stats(window_data)\n",
    "\n",
    "        # --- Run inference ---\n",
    "        print(\"\\n3. Testing inference...\")\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        posterior_samples, diagnostics = infer_parameters_snle(\n",
    "        snle,\n",
    "        model_data['snle_params'],\n",
    "        observed_stats, \n",
    "        model_data['y_mean'], model_data['y_std'],\n",
    "        num_samples=5_000,\n",
    "        num_warmup=50,\n",
    "        num_chains=2,\n",
    "        rng_key=subkey\n",
    "        )\n",
    "\n",
    "        # --- Plot posterior distributions ---\n",
    "        for i in range(4):\n",
    "\n",
    "            # Compute histogram\n",
    "            counts, bins, _ =axes[i].hist(posterior_samples[:, i], bins=30, color=colors_rgba[session_i], edgecolor=None, alpha=0.3)\n",
    "\n",
    "            # Posterior mode (bin center with max count)\n",
    "            mode_index = jnp.argmax(counts)\n",
    "            posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "            # axes[i].axvline(true_theta[i], color=colors_rgba[drift_i], linestyle='-', label=\"true value\",alpha=0.5)\n",
    "            axes[i].axvline(posterior_mode, color=colors_rgba[session_i], linestyle=':', label='MAP estimate',alpha=0.5)\n",
    "\n",
    "            axes[i].set_xlabel(param_names[i])\n",
    "            axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "            axes[i].set_xlim(model_data['config']['prior_low'][i], model_data['config']['prior_high'][i])\n",
    "\n",
    "        axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8475a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- Plot posterior distributions ---\n",
    "for i in range(4):\n",
    "\n",
    "    # Compute histogram\n",
    "    counts, bins, _ =axes[i].hist(posterior_samples[:, i], bins=30, color=colors_rgba[session_i], edgecolor=None, alpha=0.3)\n",
    "\n",
    "    # Posterior mode (bin center with max count)\n",
    "    mode_index = jnp.argmax(counts)\n",
    "    posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "    # axes[i].axvline(true_theta[i], color=colors_rgba[drift_i], linestyle='-', label=\"true value\",alpha=0.5)\n",
    "    axes[i].axvline(posterior_mode, color=colors_rgba[session_i], linestyle=':', label='MAP estimate',alpha=0.5)\n",
    "\n",
    "    axes[i].set_xlabel(param_names[i])\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axes[i].set_xlim(model_data['config']['prior_low'][i], model_data['config']['prior_high'][i])\n",
    "\n",
    "axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "for session_i in range(2):\n",
    "    window_data = session_windows[session_i,:,:]\n",
    "\n",
    "    positions = window_data[ :, 0]\n",
    "    rewards = window_data[ :, 1]\n",
    "    stopped = window_data[ :, 2]\n",
    "\n",
    "    plt.plot(np.where(rewards)[0],window_data[rewards==1,0]/88.58,'ob')\n",
    "    plt.plot(np.where(rewards==0)[0],window_data[rewards==0,0]/88.58,'xr')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for session_i in range(2):\n",
    "\n",
    "    theta = jnp.array([0.05, 0.5, 0.4, 0.2])  # mid-range parameters\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    sim_window_data, _ = simulator.simulate_one_window(theta, subkey)\n",
    "\n",
    "    # Extract data\n",
    "    positions = sim_window_data[ :, 0]\n",
    "    rewards = sim_window_data[ :, 1]\n",
    "    stopped = sim_window_data[ :, 2]\n",
    "\n",
    "    plt.plot(np.where(rewards)[0],sim_window_data[rewards==1,0],'ob')\n",
    "    plt.plot(np.where(rewards==0)[0],sim_window_data[rewards==0,0],'xr')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_theta = 1\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "param_labels = [\n",
    "    \"drift_rate: evidence accumulation rate\",\n",
    "    \"reward_bump: evidence boost from receiving reward\",\n",
    "    \"failure_bump: evidence boost from not receiving reward\",\n",
    "    \"noise_std: std of noise in evidence accumulation\"\n",
    "]\n",
    "\n",
    "number_of_samples = 5\n",
    "cmap = mpl.colormaps['rainbow']\n",
    "\n",
    "# 3. Sample the colormap at regular intervals from 0 to 1\n",
    "# This returns an array of RGBA tuples\n",
    "gradient = np.linspace(0, 1, number_of_samples)\n",
    "colors_rgba = cmap(gradient)\n",
    "theta_values = np.linspace(model_data['config']['prior_low'][vary_theta], \n",
    "                           model_data['config']['prior_high'][vary_theta], \n",
    "                           number_of_samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- Simulate observed data ---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "rng_key = random.PRNGKey(111)\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "true_theta = prior_fn().sample(seed=subkey)['theta']\n",
    "\n",
    "for theta_i, theta in enumerate(theta_values):\n",
    "    true_theta = true_theta.at[vary_theta].set(theta)\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "    print(f\"   True theta: {true_theta}\")\n",
    "\n",
    "    # --- Run inference ---\n",
    "    print(\"\\n3. Testing inference...\")\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    posterior_samples, diagnostics = infer_parameters_snle(\n",
    "    snle,\n",
    "    model_data['snle_params'],\n",
    "    observed_stats, \n",
    "    model_data['y_mean'], model_data['y_std'],\n",
    "    num_samples=1000,\n",
    "    num_warmup=50,\n",
    "    num_chains=2,\n",
    "    rng_key=subkey\n",
    "    )\n",
    "\n",
    "    # --- Plot posterior distributions ---\n",
    "    for i in range(4):\n",
    "\n",
    "        # Compute histogram\n",
    "        counts, bins, _ =axes[i].hist(posterior_samples[:, i], bins=30, color=colors_rgba[theta_i], edgecolor=None, alpha=0.3)\n",
    "\n",
    "        # Posterior mode (bin center with max count)\n",
    "        mode_index = jnp.argmax(counts)\n",
    "        posterior_mode = (bins[mode_index] + bins[mode_index + 1]) / 2\n",
    "\n",
    "        axes[i].axvline(true_theta[i], color=colors_rgba[theta_i], linestyle='-', label=\"true value\",alpha=0.5)\n",
    "        axes[i].axvline(posterior_mode, color=colors_rgba[theta_i], linestyle=':', label='MAP estimate',alpha=0.5)\n",
    "\n",
    "        axes[i].set_xlabel(param_names[i])\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "        axes[i].set_xlim(model_data['config']['prior_low'][i], model_data['config']['prior_high'][i])\n",
    "\n",
    "    axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c95f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def pairplot(posterior_samples, true_params=None, param_names=None, \n",
    "             figsize_per_param=2.5, grid_points=100, fig=None, axes=None,\n",
    "             color_i = 1):\n",
    "    \"\"\"\n",
    "    Lower-triangle corner plot with:\n",
    "    - 2D filled KDEs (off-diagonal)\n",
    "    - 1D KDEs (diagonal)\n",
    "    - Red 'X' for true parameters\n",
    "    \"\"\"\n",
    "\n",
    "    cmaps = ['Purples', 'Blues', 'Greens', 'Oranges', 'Reds']\n",
    "    color = plt.cm.get_cmap(cmaps[color_i])(1.)\n",
    "\n",
    "    if isinstance(posterior_samples, jnp.ndarray):\n",
    "        posterior_samples = np.array(posterior_samples)\n",
    "    \n",
    "    n_params = posterior_samples.shape[1]\n",
    "    if param_names is None:\n",
    "        param_names = [f\"param{i}\" for i in range(n_params)]\n",
    "    \n",
    "    if fig is None or axes is None:\n",
    "        fig, axes = plt.subplots(n_params, n_params, figsize=(figsize_per_param*n_params, figsize_per_param*n_params))\n",
    "    \n",
    "    for i in range(n_params):\n",
    "        for j in range(n_params):\n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            # Only fill lower triangle\n",
    "            if i < j:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            \n",
    "            # Diagonal: 1D KDE\n",
    "            if i == j:\n",
    "                data = posterior_samples[:, i]\n",
    "                kde = gaussian_kde(data)\n",
    "                x_grid = np.linspace(data.min(), data.max(), grid_points)\n",
    "                ax.fill_between(x_grid, kde(x_grid), color=color, alpha=0.5)\n",
    "                \n",
    "                if true_params is not None:\n",
    "                    ax.axvline(true_params[i], color=color, linestyle='-', lw=1)\n",
    "            \n",
    "            # Off-diagonal: 2D KDE\n",
    "            else:\n",
    "                x = posterior_samples[:, j]\n",
    "                y = posterior_samples[:, i]\n",
    "                xy = np.vstack([x, y])\n",
    "                kde = gaussian_kde(xy)\n",
    "                x_grid = np.linspace(x.min(), x.max(), grid_points)\n",
    "                y_grid = np.linspace(y.min(), y.max(), grid_points)\n",
    "                X, Y = np.meshgrid(x_grid, y_grid)\n",
    "                Z = kde(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "\n",
    "                # Define the threshold\n",
    "                threshold = .5\n",
    "\n",
    "                # Mask values below the threshold\n",
    "                Z_masked = np.ma.masked_where(Z < threshold, Z)\n",
    "\n",
    "                ax.contourf(X, Y, Z_masked, levels=20, cmap=cmaps[color_i], alpha=0.7)\n",
    "                \n",
    "                if true_params is not None:\n",
    "                    ax.scatter(true_params[j], true_params[i], c=color, s=50, marker='X', label='True')\n",
    "            \n",
    "            # Only label left and bottom axes\n",
    "            if i < n_params - 1:\n",
    "                ax.set_xticklabels([])\n",
    "            else:\n",
    "                ax.set_xlabel(param_names[j])\n",
    "            if j > 0:\n",
    "                ax.set_yticklabels([])\n",
    "            else:\n",
    "                ax.set_ylabel(param_names[i])\n",
    "    \n",
    "    # Add a legend in the top-left subplot\n",
    "    handles = []\n",
    "    if true_params is not None:\n",
    "        handles.append(plt.Line2D([0], [0], marker='X', color='w', markerfacecolor=color, markersize=8, label='True'))\n",
    "    axes[0, 1].legend(handles=handles, loc='upper left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_per_param=2.0\n",
    "n_params = posterior_samples.shape[1]\n",
    "fig, axes = plt.subplots(n_params, n_params, figsize=(figsize_per_param*n_params, figsize_per_param*n_params))\n",
    "pairplot(posterior_samples, true_theta, param_names, figsize_per_param=figsize_per_param, fig=fig, axes=axes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82adf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_theta = 0\n",
    "number_of_samples = 5\n",
    "param_names = [\"drift_rate\", \"reward_bump\", \"failure_bump\", \"noise_std\"]\n",
    "param_labels = [\n",
    "    \"drift_rate: evidence accumulation rate\",\n",
    "    \"reward_bump: evidence boost from receiving reward\",\n",
    "    \"failure_bump: evidence boost from not receiving reward\",\n",
    "    \"noise_std: std of noise in evidence accumulation\"\n",
    "]\n",
    "\n",
    "cmap = mpl.colormaps['rainbow']\n",
    "# 3. Sample the colormap at regular intervals from 0 to 1\n",
    "# This returns an array of RGBA tuples\n",
    "gradient = np.linspace(0, 1, number_of_samples+2)[1:-1]\n",
    "colors_rgba = cmap(gradient)\n",
    "theta_values = np.linspace(model_data['config']['prior_low'][vary_theta], \n",
    "                           model_data['config']['prior_high'][vary_theta], \n",
    "                           number_of_samples+2)[1:-1]\n",
    "\n",
    "figsize_per_param=2.0\n",
    "n_params = posterior_samples.shape[1]\n",
    "fig, axes = plt.subplots(n_params, n_params, figsize=(figsize_per_param*n_params, figsize_per_param*n_params))\n",
    "\n",
    "# --- Simulate observed data ---\n",
    "print(\"\\n2. Simulating observed data...\")\n",
    "rng_key = random.PRNGKey(666)\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "true_theta = prior_fn().sample(seed=subkey)['theta']\n",
    "\n",
    "for theta_i, theta in enumerate(theta_values):\n",
    "    true_theta = true_theta.at[vary_theta].set(theta)\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    _, observed_stats = simulator.simulate_one_window(true_theta, subkey)\n",
    "    print(f\"   True theta: {true_theta}\")\n",
    "\n",
    "    # --- Run inference ---\n",
    "    print(\"\\n3. Testing inference...\")\n",
    "    rng_key, subkey = random.split(rng_key)\n",
    "    posterior_samples, diagnostics = infer_parameters_snle(\n",
    "    snle,\n",
    "    model_data['snle_params'],\n",
    "    observed_stats, \n",
    "    model_data['y_mean'], model_data['y_std'],\n",
    "    num_samples=1000,\n",
    "    num_warmup=50,\n",
    "    num_chains=2,\n",
    "    rng_key=subkey\n",
    "    )\n",
    "\n",
    "    # --- Plot posterior distributions ---\n",
    "    pairplot(posterior_samples, true_theta, param_names, \n",
    "             figsize_per_param=figsize_per_param, fig=fig, axes=axes, \n",
    "             color_i=theta_i)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697322be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4fd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_jax_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
